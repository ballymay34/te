1. Алгоритм. Память и время как ресурсы.
Алгоритм – это набор шагов или инструкций, необходимых для выполнения задач. Алгоритм – это набор конечного числа правил, задающих последовательность выполнения операций компьютерной программой для решения задач определенного типа.
Свойства алгоритма:
• Конечность: Алгоритм всегда должен заканчиваться после выполнения определенного количества шагов.
• Определенность: Действия, которые нужно выполнить, должны быть строго и недвусмысленно определены для каждого возможного случая.
• Ввод: Алгоритм имеет некоторое(возможно равное нулю) число входных данных.
• Вывод: У алгоритма есть одно или несколько выходных данных, т.е. величин, имеющих вполне определенную связь с входными данными.
• Эффективность: Алгоритм считается эффективным, если все его операторы достаточно просты для того, чтобы их можно было точно выполнить в течение конечного промежутка времени с помощью карандаша и бумаги.
 
Обычно у алгоритма две сложности:
• Временная сложность – как количество операций, которые выполняются при работе алгоритма, связано с объемом входных данных.
• Сложность по памяти – как количество памяти, которое нужно алгоритму, связано с размером входных данных.
Память
Память – это объем оперативной памяти, который потребуется алгоритму для работы. Например, одна переменная – одна ячейка памяти, а массив – это больше ячеек памяти. Для анализа алгоритма обычно используется анализ пространственной сложности алгоритма, чтобы оценить необходимую память времени исполнения как функцию от размера входа. Результат обычно выражается в терминах “О” большое.
Существует 4 аспекта использования памяти:
• Количество памяти, необходимое для хранения кода алгоритма.
• Количество памяти, необходимое для входных данных.
• Количество памяти, необходимое для любых выходных данных(но некоторые алгоритмы, такие как сортировка, часто переставляют входные данные и не требуют памяти для выходных) • Количество памяти, необходимое для вычислительного процесса во время вычислений. (именованные переменные, любое стековое пространство, необходимое для вызова подпрограмм, которое может быть существенным при использовании рекурсии)
Время
Время – это … время, которое нужно алгоритму для обработки данных. Время считают не в секундах и минутах, а в количестве операций, которые алгоритм совершит. Для анализа алгоритма обычно используется анализ временной сложности алгоритма, чтобы оценить время работы как функцию от размера входных данных. Результат обычно выражается в терминах “О” большое.
2. O-символика как инструмент оценки ресурсов, различные асимптотики (логарифм, полином, экспонента).
O-символика, или асимптотическая запись, - это система символов, позволяющая оценить время выполнения алгоритма, устанавливая зависимость времени выполнения от увеличения объёма входных данных[1]. Она также известна как оценка сложности алгоритмов.
Существует несколько видов асимптотической нотации, которые используются для оценки сложности алгоритмов:

Например, для алгоритма сортировки пузырьковой метод имеет временную сложность O(n^2), а алгоритм быстрого сортировки имеет временную сложность O(n log n).
Асимптотическая нотация позволяет сравнивать различные алгоритмы и определить, какой из них более эффективен для конкретной задачи. Однако стоит учитывать, что в реальных условиях выполнения алгоритмов могут влиять дополнительные факторы, такие как размер памяти, скорость процессора и другие характеристики компьютерной системы.
Метод математической индукции, использование для доказательства оценок.
3. Метод математической индукции, использование длядоказательства оценок.
Индукция – это переход от общего к частному.
Метод используется для доказательства тех или иных утверждений с натуральными числами.
Он заключается в следующем: некоторое утверждение справедливо для всякого натурального n, если:
		Оно справедливо для n=1 и
Из справедливости утверждения для какого-либо произвольного натурального n = k следует его справедливость для n = k+1
Пример: 1=1^2, 1+3=2^2, 1+3+5=3^2.
Если что: 1^2 – это один во второй степени.
4. Алгоритмы для работы с большими числами: сложение,умножение, быстрое возведение в степень
Для арифметики с большими числами (сложение и умножение) есть различные алгоритмы (алг. Карацубы, Фюрера и др). Однако вполне применимы наивные алгоритмы, которые основаны на сложении и умножении в столбик.
Так, можно представить два числа в виде массивов, каждый элемент которых содержит цифру в разряде числа. Для удобства следует сделать оба списка одинаковыми по длине, т.е. в список числа с наименьшим количеством разрядов стоит добавить ведущие нули. Теперь, проходясь циклом по всем разрядам чисел от младших к старшим, будем складывать каждый разряд и записывать его результат по модулю 10, а при переходе через разряд добавлять 1 к следущему разряду.
Аналогичным образом работает алгоритм умножения (реализацию обоих алгоритмов можно найти в практических вопросах). Сложность алгоритма сложения - O(n) где n - количество разрядов в более длинном числе, а умножения - O(n*m) где n и m - количества разрядов в числах.
Бинарное возведение в степень - алгоритм возведения в степень, основывающийся на свойстве степеней - (a^n)*(a^m)=a^(n+m)
Можно вывести следущее соотношение:

Данная задача как правило решается за счёт нисходящей рекурсии и имеет сложность O(log n) Примеры этих алгоритмов можно найти в практике.
5. Арифметика по модулю: сложение, умножение, возведение встепень

 
Это необходимо для оптимизации вычислений при работе с большими числами: если результат необходимо искать по модулю, то можно оперировать остатками по этому же модулю при математических операциях. 
6. Алгоритм Евклида, расширенный алгоритм Евклида.


7. Проверка чисел на простоту, решето Эратосфена.


8. Криптография: схемы с закрытым ключом, RSA.
**RSA(аббревиатура от фамилий Rivest, Shamir и Adleman)** – криптографический алгоритм с открытым ключом, основывающийся на вычислительной сложности задачи факторизации больших полупростых чисел. 
 
Например: 592939 * 592967 = 351593260013. Но как имея только число 351593260013 узнать числа 592939 и 592967? Это называется “сложность задачи факторизации произведения двух больших простых чисел”, т.е. в одну сторону просто, а в обратную невероятно сложно. 
 
Используется при обмене данными и в качестве цифровой подписи. Является базовой частью протокола HTTPS.(более подробный процесс как это все происходит смотрите в лекции 2. Там все продемонстрировано на картинках) 
 

9. Квадратичные сортировки (вставками и пузырьковая).


for iin range(N): 
    a.append(randint(1, 99)) print(a)  for iin range(N-1): for jin range(N-i-1): 
if a[j] > a[j+1]: 
            a[j], a[j+1] = a[j+1], a[j] 
 print(a) 
``` 
 С помощью while: 
 ``` from randomimport randint 
 N = 10 a = [] for iin range(N): 
    a.append(randint(1, 99)) print(a)  i = 0 while i < N - 1: 
    j = 0 while j < N - 1 - i: if a[j] > a[j+1]: 
            a[j], a[j+1] = a[j+1], a[j]         j += 1     i += 1 
 print(a) 
``` 
 
**Сортировка вставками** 
 
В начальный момент отсортированная последовательность пуста. На каждом шаге алгоритма выбирается один из элементов входных данных и помещается на нужную позицию в уже отсортированной последовательности до тех пор, пока набор входных данных не будет исчерпан. 
 
Данный алгоритм можно ускорить при помощи использования бинарного поиска для нахождения места текущему элементу в отсортированной части. Проблема с долгим сдвигом массива вправо решается при помощи смены указателей. 
 ``` def insertion_sort(list1):     for i in range(1, len(list1)): 
        value = list1[i] 
10. Метод «разделяй и властвуй». Бинарный поиск.
**“Разделяй и властвуй”** в информатике – это схема разработки алгоритмов, заключающаяся в рекурсивном разбиении решаемой задачи на две или более подзадачи того же типа, но меньшего размера, и комбинировании их решений для получения ответа к исходной задаче; разбиения выполняются до тех пор, пока все подзадачи не окажутся элементарными. 
 
Данный метод применяется в таких алгоритмах как бинарный(двоичный) поиск и сортировка слиянием. 
 
**Бинарный(двоичный) поиск** 
 
Дана таблица записей R1, R2, …Rn, ключи которых расположены в порядке возрастания: K1<K2<..<Kn, алгоритм используется для поиска заданного аргумента K. 
 
1. Установить I <- 1, u <- N 
2. Если u<I, алгоритм завершается неудачно; иначе установить I <- 
floor((l+u)/2), чтобы I соответствовало примерно середине рассматриваемой части таблицы. 
3. Если K<Ki, перейти к шагу 4; если K>Ki, перейти к шагу 5, если K=Ki, алгоритм успешно завершается. 4. Установить u <- i-1 и перейти к шагу 2. 
5. Установить I <- i+1 и перейти к шагу 2. 
 
Сложность: O(logn) 
11. Сортировка слиянием: наивная и эффективная реализация.
1. Сортируемый массив разбивается на две части примерно одинакового размера. Рекурсивное разбиение задачи на меньшие происходит до тех пор, пока размер массива не достигнет единицы(любой массив длины 1 можно считать упорядоченным) 2. Каждая из получившихся частей сортируется отдельно, например – тем же самым алгоритмом. 
3. Два упорядоченных массива половинного размера соединяются в один. 

 
a. На каждом шаге мы берем меньшей из двух первых элементов подмассивов и записываем его в результирующий массив. Счетчики номеров элементов результирующего массива и подмассива, из которого был взят элемент, увеличиваем на 1. 
 
b. Когда один из подмассивов закончился, мы добавляем все оставшиеся элементы второго подмассива в результирующий массив. 
 
```python def merge(A, B): 
    i, j, C = 0, 0, []     while True: 
        if A[i] < B[j]: 
            C.append(A[i])             i += 1             if i == len(A): 
                C.extend(B[j:])                 break         else:             C.append(B[j])             j += 1             if j == len(B): 
                C.extend(A[i:])                 break     return C 
``` 
 
```python def top_down_merge_sort(A):     if len(A) == 1:         return A  
    d = len(A) // 2     left = top_down_merge_sort(A[:d])     right = top_down_merge_sort(A[d:])     return merge(left, right) 
 def bottom_up_merge_sort(A): 
    k = 1     while k < len(A):         for i in range(0, len(A) - k, 2 * k):             A[i:i + 2 * k] = merge(A[i:i + k], A[i + k:i + 2 * k])         k *= 2     return A 
``` 
 
Эффективная реализация включает в себя Galloping и Chunking: 
 
Сортировка слиянием. Галопирование(galloping) 
12. Быстрая сортировка: понятие вероятностного алгоритма, времяработы в среднем, простейший алгоритм, inplace-алгоритм.
Быстрая сортировка, сортировка Хоара – алгоритм сортировки, разработанный англ информатиком Тони Хоаром в 1960 году. 
 
Один из самых быстрых известных универсальных алгоритмов сортировки массивов: в среднем O(logn) обменов при упорядочении n элементов. 
 В среднем время выполнения быстрой сортировки составляет **O(n log n)**. 
 
Алгоритм: 
 
1. Подмассивы a[I..q] и a[q+1…r] сортируются с помощью рекурсивного вызова процедуры быстрой сортировки. 2. Поскольку массивы сортируются на месте, для их объединения не требуется никакие действия: весь массив a[I…r] оказывается отсортированным. 
    1. Массив a[l…r] разбивается на два (возможно пустых) подмассива a[l…q] и a[q+1..r], таких, что каждый элемент a[I…q] меньше или равен a[q], который в свою очередь, не превышает любой элемент подмассива a[q+1…r]. Индекс вычисляется в ходе процедуры разбиения. 
 ```python def partition(array, low, high): 
    pivot = array[high]     i = low - 1     for j in range(low, high):         if array[j] <= pivot: 
            i = i + 1             (array[i], array[j]) = (array[j], array[i])     (array[i + 1], array[high]) = (array[high], array[i + 1])     return i + 1  def quicksort(array, low, high): 
    if low < high         pi = partition(array, low, high)         quicksort(array, low, pi - 1)         quicksort(array, pi + 1, high) 
 
``` 
 
Вероятностный алгоритм – это алгоритма, предусматривающий обращение на определённых этапах своей работы к генератору случайных чисел с целью получения экономии во времени работы за счёт замены абсолютной достоверности результата достоверностью с некоторой вероятностью 
 
Inplace-алгоритм –  **алгоритм** не использует дополнительное пространство для манипулирования входными данными, но может потребовать небольшого, хотя и непостоянного дополнительного пространства для своей работы. (если кратко:это алгоритм, который не занимает память.) 
13. Динамическое программирование. Общие принципыдинамического программирования. Восстановление ответа.
**Динамическое программирование** – способ решения сложных задач путем разбиения их на более простые подзадачи. Он применим к задачам с оптимальной подструктурой, выглядящим как набор перекрывающихся подзадач, сложность которых чуть меньше исходной. В этом случае время вычислений можно значительно сократить. 
 **Принципы ДП:** 
 
- Метод динамического программирования сверху(мемоизация, ленивая динамика) – это простое запоминание результатов решения тех подзадач, которые могут повторно встретиться в дальнейшем. 
- Динамическое программирование снизу(табулация) – включает в себя переформулирование сложной задачи в виде рекурсивной последовательности более простых подзадач. 
 
**Основная идея динамического программирования состоит в том, чтобы:**  
1. Свести задачу для N к задаче для чисел, меньших, чем N (с помощью формулы) 
2. Хранить все ответы в массиве 
3. Заполнить начало массива вручную(для которых формула не работает) 
4. Обойти массив и заполнить ответы по формуле 
5. Вывести ответ откуда-то из этого массива 
14. Наибольшая возрастающая подпоследовательность.
Алгоритм поиска наибольшей возрастающей подпоследовательности. Рассмотрим последовательность чисел a 1 , a 2 , …, a n. Если вычеркнуть из этой последовательности часть чисел, мы получим другую последовательность, которую называют подпоследовательностью данной последовательности. Рассмотрим теперь еще одну последовательность b 1 , b 2 , …, b m. Требуется найти длину самой длинной подпоследовательности последовательности {a I }, которая одновременно является и подпоследовательностью последовательности {b I }. Такую последовательность называют наибольшей общей подследовательностью (НОП). Например, для 
последовательностей 1, 2, 3, 4, 5 и 2, 7, 3, 2, 5 НОП является подпоследовательность 2, 3, 5, состоящая из трёх членов.  
Опишем подзадачи, на которые мы будем разбивать нашу задачу. Мы напишем функцию LCS(p, q), которая находит длину НОП для двух начальных участков a1 … ap и b1… bq наших последовательностей. Пусть для всех пар q и p (p < n, q < m), мы задачу решать уже научились. Попробуем вычислить LCS(n, m). Рассмотрим два случая:  
1. an = b m 
. Тогда LCS(n, m)=LCS(n-1, m-1)+1. 

15. Дискретная задача о рюкзаке.
Задача о рюкзаке(Knapsack problem) – дано N предметов, ni(i-степень) имеет массу wi(i-степень) >0 и стоимость pi(i-степень) > 0. Необходимо выбрать из этих предметов такой набор, чтобы суммарная масса не превосходила заданной величины W(вместимость рюкзака), а суммарная стоимость была максимальна.  
Задачу о рюкзаке можно решить несколькими способами: 
 
- Перебирать все подмножества набора из N предметов. Сложность такого решения O(2^n) 
- Методом Meet-in-the-middle. Сложность решения O(2^n/2 * N) 
- Метод динамического программирования. Сложность – O(NW) 
 
Для решения построим таблицу размерности N на W, где столбцы соответствуют объему рюкзака, а строки отдельным предметам. В общем случае формула для стоимости в каждой ячейке выглядит так: 
 
S[i, j] = max (S[i?1, j], цена i-го предмета + S[i?1, j?вес i-го предмета]), где i — номер строки, j — столбца. 
16. Редакционное расстояние.

17. Односвязный список, двусвязный список.
**Линейный однонаправленный список** – это структура данных, состоящая из элементов одного типа, связанных между собой последовательно посредством указателей. Каждый элемент списка имеет указатель на следующий элемент. Последний элемент списка указывает на NULL. Элемент, на который нет указателя, является первым(головным) элементом списка. Здесь ссылка в каждом узле указывает на следующий узел в списке. В односвязном списке можно передвигаться только в сторону конца списка. Узнать адрес предыдущего элемента, опираясь на содержимое текущего узла, невозможно. 
 
В информатике линейный список обычно определяется как абстрактный тип данных(АТД), формализующий понятие упорядоченной коллекции данных. На практике линейные списки обычно реализуются при помощи массивов и связных списков.  
АТД нетипизированного изменяемого списка может быть определен как набор из конструктора и основных операций: 
 
- Операция, проверяющая список на пустоту. - Три операции добавления объекта в список (в начало, конец или внутрь после любого (n-го) элемента списка) 
- Операция, вычисляющая первый (головной) элемент списка 
- Операция доступа к списку, состоящему из всех элементов исходного списка, кроме первого. 
 
**Характеристики:** 
 
- Длина списка. Количество элементов в списке. 
- Списки могут быть типизированными и нетипизированными. Если список типизирован, то тип его элементов задан, и все его элементы должны иметь типы, совместимые с заданным типом элементов списка. 
- Список может быть сортированным или несортированным. 
- В зависимости от реализации может быть возможен произвольным доступ к элементам списка  
**Двусвязный список** 
 
**Двусвязный список (двунаправленный связный список) -** ссылки в каждом узле указывают на предыдущий и на последующий узел в списке. Как и односвязный список, двусвязный допускает только последовательный доступ к элементам, но при этом дает возможность перемещения в обе стороны. В этом списке проще производить удаление и перестановку элементов, так как легко доступны адреса тех элементов списка, указатели которых направлены на изменяемый элемент. 
 
**Как применяют связные списки:** 
 
- Для построения более сложных структур данных. 
- Для реализаций файловых систем. 
- Для формирования хэш-таблиц. 
- Для выделения памяти в динамических структурах данных. 
18. Стек.
*Стек (stack — стопка*) — структура данных, представляющая из себя упорядоченный набор элементов, в которой добавление новых элементов и удаление существующих производится с одного конца, называемого вершиной стека. Притом первым из стека удаляется элемент, который был помещен туда последним, то есть в стеке реализуется стратегия «последним вошел — первым вышел» (last-in, first-out — LIFO). 
**Операции стека:** 
? empty — проверка стека на наличие в нем элементов, ? push (запись в стек) — операция вставки нового элемента, 
? pop (снятие со стека) — операция удаления нового элемента. 

19. Очередь.
*Очередь (queue)* — это структура данных, добавление и удаление элементов в которой происходит путём операций push и pop соответственно. Притом первым из очереди удаляется элемент, который был помещен туда первым, то есть в очереди реализуется принцип «первым вошел — первым вышел» (first-in, first-out — FIFO). У 
очереди имеется голова (head) и хвост (tail). Когда элемент ставится в очередь, он 
занимает место в её хвосте. Из очереди всегда выводится элемент, который находится в ее голове. 
**Очередь поддерживает следующие операции:** 
? empty — проверка очереди на наличие в ней элементов, 
? push (запись в очередь) — операция вставки нового элемента, 
? pop (снятие с очереди) — операция удаления нового элемента, 
? size — операция получения количества элементов в очереди. 
**Как применяют очереди:** 
? Для реализации очередей, например на доступ к определённому ресурсу. 
? Для управления потоками в многопоточных средах. 
? Для генерации значений. 
? Для создания буферов. 
20. Дек.
*Дек (deque — double ended queue)* — структура данных, представляющая из себя список элементов, в которой добавление новых элементов и удаление существующих производится с обоих концов. Эта структура поддерживает как FIFO, так и LIFO, поэтому на ней можно реализовать как стек, так и очередь. В первом случае нужно использовать только методы головы или хвоста, во втором — методы push и pop двух разных концов. Дек можно воспринимать как двустороннюю очередь. 
 
**Дек имеет следующие операции:** 
? empty — проверка на наличие элементов, 
? pushBack (запись в конец) — операция вставки нового элемента в конец, 
? popBack (снятие с конца) — операция удаления конечного элемента, 
? pushFront (запись в начало) — операция вставки нового элемента в 

21. Куча.
*Куча* — это полное двоичное дерево, удовлетворяющее свойству кучи: если узел A — это родитель узла B, то ключ узла A ? ключ узла B. ? Если любой узел всегда больше дочернего узла (узлов), а ключ корневого узла является наибольшим среди всех остальных узлов, это max-куча. 
? Если любой узел всегда меньше дочернего узла (узлов), а ключ корневого узла является наименьшим среди всех остальных узлов, это min-куча. 
22. Графы. Способы хранения: матрица смежности, спискисмежности, матрица инцидентности.
**Граф** — математическая абстракция реальной системы любой природы, объекты которой обладают парными связями. Граф как математический объект есть совокупность двух множеств — множества самих объектов, называемого множеством вершин, и множества их парных связей, называемого множеством рёбер. Элемент множества рёбер есть пара элементов множества вершин. 
 **Виды графов:** 
 
**Простой (неориентированный)** граф G(V,E) есть совокупность двух множеств – непустого множества V и множества E неупорядоченных пар различных элементов множества V. Множество V называется множеством вершин, множество E называется множеством рёбер. 
 
**Ориентированный граф (орграф)** G(V,E) есть совокупность двух множеств – непустого множества V и множества E дуг или упорядоченных пар различных элементов множества V. 
 
**Взвешенный граф** — граф, каждому ребру которого поставлено в соответствие некое значение (вес ребра). 
 
Путь - любая последовательность вершин, в которой каждые две соседние вершины соединены ребром (A ? C ? B ? G, A ? D ? B ? D ? B). Длина пути - количество рёбер в нём (3 и 4 соответственно для примеров выше). Цикл - путь, у которого начальная и конечная вершина совпадают (A ? C ? B ? D ? A, F ? E ? F). Простой путь - путь, в котором нет повторяющихся рёбер. Простой цикл - цикл, который является простым путём. 
 
**Способы хранения графов:** 

 
Матрицей смежности A=||?i,j|| невзвешенного графа G=(V,E) называется матрица A[V?V], в которой ?i,j — количество рёбер, соединяющих вершины vi и vj , причём при i=j каждую петлю учитываем дважды, если граф не является ориентированным, и один раз, если граф ориентирован. Матрицей смежности A=||?i,j|| взвешенного графа G=(V,E) называется матрица A[V?V], в которой ?i,j — вес ребра, соединяющего вершины vi и vj . 
 
Матрица смежности: 
 ``` class Graph(object): 
 def __init__(self, size): 
  self.adjMatrix = [[0] * size for i in range(size)]   self.size = size  def add_edge(self, v1, v2): 
  if v1 == v2: 
   print(f"Та же вершина {v1} и {v2}")    self.adjMatrix[v1][v2] = 1    self.adjMatrix[v2][v1] = 1  def __len__(self):   return self.size  def remove_edge(self, v1, v2):   if self.adjMatrix[v1][v2] == 0: 
   print(f"Нет ребра между {v1} и {v2}")    return 
  self.adjMatrix[v1][v2] = 0   self.adjMatrix[v2][v1] = 0  def print_matrix(self): 
  for row in self.adjMatrix:    for val in row: 
    print(f'{val:4d}')    print  
``` 
 
**Плюсы матрицы смежности:** 
 
- Добавление ребра, удаление ребра, проверка наличия ребра между вершинами i и j за O(n) 
- Лучший выбор для плотных графов. В случае разреженного графа и матрицы смежности можно использовать структуры данных для разреженных матриц 
- Возможность выполнения операция на GPU 
 
**Минусы:** 
 
- Требуется VxV памяти для хранения. Чаще всего графы не имеют большого количества связей и лучшим выбором будут списки смежности. - Выполнения операций по нахождению внешних и внутренних ребер требует большего времени. 
 
Еще один способ хранения - **Списки смежности** 
 Список смежности — один из способов представления графа в виде коллекции списков вершин. Каждой вершине графа соответствует список, состоящий из 
«соседей» этой вершины. 
 
Список смежности: 
 ``` graph = {'A': set(['B', 'C']), 
 'B': set(['A', 'D', 'E']), 
 'C': set(['A', 'F']),  'D': set(['B']), 
 'E': set(['B', 'F']),  'F': set(['C', 'E'])} 
```  ``` class AdjNode:  def __init__(self, value): 
  self.vertex = value   self.next = None class Graph:  def __init__(self, num): 
  self.V = num 
  self.graph = [None] * self.V  def add_edge(self, s, d):   node = AdjNode(d)   node.next = self.graph[s]   self.graph[s] = node   node = AdjNode(s)   node.next = self.graph[d]   self.graph[d] = node 
  def print_agraph(self):   for i in range(self.V):    print("Вершина " + str(i) + ":", end="")    temp = self.graph[i]    while temp: 
    print(f" -> {temp.vertex}", end="")     temp = temp.next    print(" \n") 
``` 
 
**Плюсы списков смежности:** 
 
- Эффективны в плане потребления памяти, так как хранится только информация о ребрах. Для больших разреженных графов могут сберечь большой объем памяти. 
- Быстрый поиск смежных вершин 
23. Поиск в глубину в неориентированных графах.
**Обход в глубину** (поиск в глубину, Depth-First Search, DFS) — один из основных методов обхода графа, часто используемый для проверки связности, поиска цикла и компонент сильной связности и для топологической сортировки. Общая идея алгоритма состоит в следующем: для каждой не пройденной вершины необходимо найти все не пройденные смежные вершины и повторить поиск для них. 
 
**Пошаговое представление:** 

24. Выделение компонент связности.
**Компонент связности** – набор вершин графа, между любой парой которых существует путь.  
Для поиска компонент связности используется обычный DFS практически без модификаций. При запуске обхода из одной вершины, он гарантированно посетит все вершины, до которых возможно добраться, то есть, всю компоненту связности, к которой принадлежит начальная вершина. Для нахождения всех компонент просто попытаемся запустить обход из каждой вершины по очереди, если мы ещё не обошли её компоненту ранее. Простейший вариант: просто заполнить список comp, где comp[i] - номер компоненты связности, к которой принадлежит вершина i. 
 ``` 
visited = [False] ? n def dfs(start): 
 visited[start] = True 

25. Поиск в глубину в ориентированных графах: ориентированныеациклические графы.
Ориентированный ациклический граф (направленный ациклический граф, DAG, directed acyclic graph) – орграф, в котором отсутствуют направленные циклы, но могут быть “параллельные” пути, выходящие из одного узла и разными путями приходящие в конечный узел. Направленный ациклический граф является обобщением дерева(точнее, их объединения – леса). 
 
Направленные ациклические графы широко используется в приложениях: в компиляторах, в искусственном интеллекте (для представления искусственных нейронных сетей без обратной связи), в статистике и машинном обучении. 
 
Нахождение цикла в орграфе: 
 
1. Пометить текущий узел как посещенный и добавить его индекс в стек. 
2. Пройти в цикле по вершинам, выполнить рекурсивный вызов функции dfs(данный шаг необходим для гарантии, что, если граф является лесом, мы проверим все подграфы): 
 
a. В каждом рекурсивном вызове найти все смежные вершины для данной вершины: 

26. Топологическая сортировка вершин.
**Топологическая сортировка для ориентированного ациклического графа(Directed** **Acyclic** **Graphs, DAG)** – это линейное упорядочение вершин, для которого выполняется следующее условие – для каждого направленного ребра uv вершина u предшествует вершине v в упорядочении. Если граф не является DAG, то топологическая сортировка для него невозможна. 
 
Например, топологическая сортировка приведенного графа – “5 4 2 3 1 0”. Для графа может существовать несколько топологических сортировок. Например, другая топологическая сортировка для этого же графа – “4 5 2 3 1 0”. Первая вершина в топологической сортировке – это всегда вершина без входящих ребер. 
 
**Алгоритм Кана** 
 
1. Вычислить количество входящих дуг для каждой вершины в графе и установить начальное значение счетчика посещенных узлов на 0. 
2. Выбрать все вершины с 0 входящих дуг и поставить их все в очередь. 
3. Добавить одну посещенную вершину к счетчику после удаления вершины из очереди. 
4. Для каждой смежной вершины уменьшить число входов на 1. 
5. Добавить вершину в очередь, если число входов любой из смежных вершин уменьшилось до 0. 
6. Пока очередь не пуста, повторять с шага 3. 
7. Топологическая сортировка невозможна для графа если число посещенных узлов не равно числу вершин графа. 
 ```python def isCyclic(self): 
    inDegree = [0] * self.V     q = deque()     visited = 0 
     for u in range(self.V):         for v in self.adj[u]:             inDegree[v] += 1 

27. Нахождение кратчайших путей из одной вершины вневзвешенных графах, поиск в ширину.
Дан невзвешенный ориентированный граф **********G = (V, E)**********, а также вершина *s*. Найти длину 
кратчайшего пути от **s** до каждой из вершин графа. Длина пути — количество рёбер в нём. 
 **Обход в ширину (Поиск в ширину, BFS, Breadth-first search)** — один из простейших алгоритмов обхода графа, являющийся основой для многих важных алгоритмов для работы с графами. 
Алгоритм работает следующим образом. 
 
1. Создадим массив ****dist**** расстояний. Изначально **********dist[s] = 0********** (поскольку расстояний от вершины до самой себя равно *0*) и 
************dist[v] = ?************ для *******v ? s*******. 
2. Создадим очередь *q*. Изначально в *q* добавим вершину *s*. 
3. Пока очередь *q* непуста, делаем следующее: 
i. Извлекаем вершину *v* из очереди. 
ii. Рассматриваем все рёбра *(v,u)?E*. Для каждого такого ребра пытаемся сделать релаксацию: если *dist[v] + 1 < dist[u*], то мы делаем присвоение 
*dist[u] = dist[v] + 1* и добавляем вершину *u* в очередь. 
 ```python def BFS(self, s):  	 visited = [False] * (max(self.graph) + 1)  	 queue = []  	 queue.append(s)  	 visited[s] = True  	 while queue: 
 	  	 s = queue.pop(0)  	  	 print(s, end=" ")  	  	 for i in self.graph[s]: 
 	  	   	if visited[i] == False:  	  	   	 	 queue.append(i) 

	 	  	   	 	 visited[i] = True 
``` 
 
**Алгоритм волновой трассировки (волновой алгоритм, алгоритм Ли)** — алгоритм поиска пути, алгоритм поиска кратчайшего пути на планарном графе. Принадлежит к алгоритмам, основанным на методах поиска в ширину. 
 
Работа алгоритма включает в себя три этапа: инициализацию, распространение волны и восстановление пути. 
 
- Во время инициализации строится образ множества ячеек обрабатываемого поля, каждой ячейке приписываются атрибуты проходимости/непроходимости, запоминаются стартовая и финишная ячейки. 
- Далее, от стартовой ячейки порождается шаг в соседнюю ячейку, при этом проверяется, проходима ли она, и не принадлежит ли ранее меченной в пути ячейке. 
- При выполнении условий проходимости и непринадлежности её к ранее помеченным в пути ячейкам, в атрибут ячейки записывается число, равное количеству шагов от стартовой ячейки, на первом шаге это будет 1. Каждая ячейка, меченная числом шагов от стартовой ячейки, становится стартовой и из неё порождаются очередные шаги в соседние ячейки. 
 
```python 
from collections import deque def lee_algorithm(matrix, start, end):  	 queue = deque()  	 visited = set()  	 distance = {start: 0}  	 prev = {} 
 
 	 queue.append(start)  	 visited.add(start) 
 
	 	 while queue: 
 	  	 node = queue.popleft()  	  	 for neighbor in get_neighbors(matrix, node): 
 	  	   	if neighbor not in visited:  	  	   	 	 visited.add(neighbor) 
 	  	   	 	 distance[neighbor] = distance[node] + 1  	  	   	 	 prev[neighbor] = node  	  	   	 	 queue.append(neighbor)  	  	   	if neighbor == end: 
        return get_shortest_path(prev, start, end)   return None 
 def get_neighbors(matrix, node):  	 neighbors = []  	 row, col = node 
 
28. Нахождение кратчайших путей из одной вершины в графах сположительными весами.
Дан взвешенный ориентированный граф ******G(V, E)******, а также вершина *s*. Длина ребра *******(u, v)******* равна *******w(u, v)*******. Длины всех рёбер неотрицательные.  
Найти длину кратчайшего пути от *s* до каждой из вершин графа. Длина пути — сумма длин рёбер в нём. 
 
**Алгоритм Дейкстры** 
 
1. Создать массив *****dist***** расстояний. Изначально ********dist[s] = 
0******** и ************dist[v] = ?************ для *******v ? s*******. 
2. Создать булёв массив ****used****, *****used[v] = 0***** для всех вершин **v** — в нём мы будем отмечать, совершалась ли релаксация из вершины. 
3. Пока существует вершина *v* такая, что ************used[v] = 0************ и *************dist[v] ? ?*************, притом, если таких вершин несколько, то **v** — вершина с минимальным *******dist[v]*******, делать следующее: 
i. Пометить, что мы совершали релаксацию из вершины *v*, то есть присвоить 

29. Алгоритм Дейкстры, оценка времени работы при различныхреализациях очереди с приоритетами (массивом, двоичной кучей).
Искать вершину с минимальным *****dist***** можно гораздо быстрее, используя такую структуру данных как очередь с приоритетом. Нам нужно хранить пары **
(dist, index)** и уметь делать такие операции: 
 
- Извлечь минимум (чтобы обработать новую вершину) 
- Удалить вершину по индексу (чтобы уменьшить *****dist***** до какого-то соседа) 
- Добавить новую вершину (чтобы уменьшить *****dist***** до какого-то соседа)  
Для этого используют, например, кучу или сет. Удобно помимо сета хранить сам массив *dist*, который его дублирует, но хранит элементы по порядку. Тогда, чтобы заменить значение ***(dist1, u)*** на **********(dist2, u)**********, нужно удалить из сета значение *(dist[u], u)*, сделать ***************dist[u] = dist2***************; и добавить в сет (******dist[u], u)****** 
 ```python import heapq 
 def calculate_distances(graph, starting_vertex): 
 	 distances = {vertex: float('inf') for vertex in graph}  	 distances[starting_vertex] = 0  	 pq = [(0, starting_vertex)]  	 while len(pq) > 0: 
 	  	 current_distance, current_vertex = heapq.heappop(pq)  	  	 if current_distance > distances[current_vertex]: 
 	  	   	continue  	  	 for neighbor, weight in graph[current_vertex].items(): 
 	  	   	distance = current_distance + weight  	  	   	if distance < distances[neighbor]:  	  	   	 	 distances[neighbor] = distance  	  	   	 	 heapq.heappush(pq, (distance, neighbor))  	 return distances 
``` 
 
Данный алгоритм будет работать за ********VO(logV)******** извлечений минимума и ********O(ElogV)******** операций уменьшения расстояния до вершины. Поэтому алгоритм работает за ***O(ElogV)***. 
 
Заметьте, что этот алгоритм не лучше и не хуже алгоритма без сета, который работает за 
*************O(V^2+ E)*************. Ведь если ***********E = O(V^2)*********** 
(граф почти полный), то Дейкстра без сета работает быстрее, а если, наример, 
*E=O(V)*, то Дейкстра на сете работает быстрее 
30. Кратчайшие пути в ациклических ориентированных графах.
Пусть дан ациклический ориентированный взвешенный граф. Требуется найти вес кратчайшего пути из *u* в *v*. 
Пусть **d** — функция, где ****d(i)**** — вес кратчайшего пути из **u** в *i*. 
Ясно, что **d(u)** равен 0. Пусть *******w(i, j)******* — вес ребра из **i** в *j*. Будем обходить граф в порядке топологической сортировки. Получаем следующие соотношения: 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/c3fc9fae-3645-42f1-adc1-5be3469dc43d/Untitled.png)  
Так как мы обходим граф в порядке топологической сортировки, то на *i*-ом шаге всем **d(j)** (*j* такие, что существует ребро из *j* в *i*) уже присвоены оптимальные ответы, и, следовательно, **d(i)** также будет присвоен оптимальный ответ. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/b5f0ae38-5671-463f-b2aa-29534cb986f2/Untitled.png)  ```python def minDist(n, w, u): 
 	 dist = [float('inf')] * n  	 dist[u] = 0 
 	 p = topSort(w)  # топологическая сортировка  	 for i in range(n)  	  	 for j in range(n):  	  	   	if w[i][j] > 0: 
	 	  	   	 	 dist[j] = min(d[j], dist[p[i]] + w[p[i]][j]) 
``` 
31. Алгоритм Беллмана-Форда, проверка наличия циклаотрицательного веса.
Для заданного взвешенного графа найти кратчайшие пути из заданной вершины до всех остальных вершин. В случае, когда в графе содержатся циклы с отрицательным суммарным весом, достижимые из , сообщить, что кратчайших путей не существует.  
**Алгоритм Беллмана-Форда** предназначен для решения задачи поиска кратчайшего пути на графе. Для заданного ориентированного взвешенного графа алгоритм находит кратчайшие расстояния от выделенной вершины-источника до всех остальных вершин графа. 
 
Алгоритм Беллмана-Форда масштабируется хуже других алгоритмов решения указанной задачи (сложность O(|V||E|) против O(|E| + |V|ln(|V|) у алгоритма Дейкстры), однако его отличительной особенностью является применимость к графам с произвольными, в том числе отрицательными, весами. 
 

Примеры рисунками как работает алгоритм Беллмана-Форда в лекции 8 в самом конце. 
 
**Алгоритм Беллмана-Форда:** 
 
1. Инициализация: всем вершинам присваивается предполагаемое расстояние dist[v] = бесконечность, кроме вершины-источника, для которой dist(u) = 0. 
2. Релаксация множества ребер E 
3. Для каждого ребра e = (v, z) принадлежащим к E, вычисляется новое предполагаемое расстояние new_dist(z) = dist(v) + w(e) 
4. Если new_dist(z) < dist(z), то происходит присваивание dist(z) = new_dist(z) (релаксация ребра e) 
5. Алгоритм производит релаксацию всех ребер графа до тех пор, пока на очередной итерации происходит релаксация хотя бы одного ребра. 
 ``` class Graph: 
    def __init__(self, vertices): 
        self.V = vertices         self.graph = [] 
     def addEdge(self, u, v, w): 
        self.graph.append([u, v, w]) 
     def printArr(self, dist): 
        print('Расстояние до стартовой')         for i in range(self.V): 
            print(f"{i}\t\t{dist[i]}") 
     def BellmanFord(self, src): 
        dist = [float("Inf")] * self.V         dist[src] = 0 
         for _ in range(self.V - 1):             for u, v, w in self.graph:                 if dist[u] != float("Inf") and dist[u] + w < dist[v]: 
                    dist[v] = dist[u] + w 
         self.printArr(dist) 
``` 
 
**Проверка наличия цикла отрицательного веса** 
 
Алгоритм Беллмана-Форда сможет бесконечно делать релаксации среди всех вершин этого цикла и вершин, достижимых из него. Следовательно, если не ограничивать число фаз числом n-1, то алгоритм будет работать бесконечно, постоянно улучшая расстояния до этих вершин. 
 
Отсюда мы получаем **критерий наличия достижимого цикла отрицательного веса**: если после n-1 фазы мы выполним еще одну фазу, и на ней произойдет хотя бы одна 
32. Кратчайшие пути между всеми парами вершин: алгоритмФлойда-Уоршелла.
**Алгоритм Флойда(алгоритм Флойда-Уоршелла) –** алгоритм нахождения длин кратчайших путей между всеми парами вершин во взвешенном ориентированном графе. Работает корректно, если в графе нет циклов отрицательной величины, а в случае, когда такой цикл есть, позволяет найти хотя бы один такой цикл. Алгоритм работает за O(n3) времени и использует O(n2) памяти. Разработан в 1962 году. Примеры реализации в картинках в 8 лекции с 25-29 стр. 
 ``` def floydWarshall(graph): 
    dist = list(map(lambda i: list(map(lambda j: j, i)), graph))     for k in range(V): 
        for i in range(V):             for j in range(V): 
                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]) 

33. Минимальное покрывающее дерево: свойство разреза.
**Остовное дерево(spanning** **tree)** графа G = (V, E) – ациклический связный подграф данного связного неориентированного графа, в который входят все его вершины.  
**Минимальное остовное дерево(или минимальное покрывающее дерево)** в 
(неориентированном) связном взвешенном графе – это остовное дерево этого графа, имеющее минимальный возможный вес, где под весом дерева понимается сумма весов входящих в него ребер. 
 
Пусть G/ – подграф некоторого минимального остовного дерева графа G = (V, E)  
Ребро (u, v) не принадлежит G/ называется **безопасным(sage** **edge),** если при добавлении его в G/, G/ объединяется с (u, v) также является подграфом некоторого минимального остовного дерева графа G. 
 
Разрезом(cut) неориентированного графа G = (V, E) называется разбиение V на два непересекающихся подмножества: S и T = V \ S. Обозначается как <S, T>  
Ребро(u, v) принадлежит E пересекает(crosses) разрез <S, T>, если один из его концов принадлежит множеству S, а другой – множеству T. 
 
**Свойство разреза** 
 
**Теорема:** Рассмотрим связный неориентированный взвешенный граф G = (V, E) с весовой функцией w: E -> R. Пусть G/ = (V, E/) – подграф некоторого минимального остовного дерева G, <S, T> - разрез G, такой, что ни одно ребро из E/ не пересекает разрез, а (u, v) – ребро минимального веса среди всех ребер, пересекающих разрез <S, T>. Тогда ребро e = (u, v) является безопасным для G/  
**Доказательство:** Достроим E/  до некоторого минимального остовного дерева, обозначим его Tmin. Если ребро e принадлежит Tmin , то лемма доказана, поэтому рассмотрим случай, когда ребро e не принадлежит Tmin. Рассмотрим путь в Tmin  от вершины u до вершины v. Так как эти вершины принадлежат разным долям разреза, то хотя бы одно ребро пути пересекает разрез, назовем его e/ . По условию леммы w(e) <= w(e/). Заменим ребро e/ в Tmin на ребро e. Полученное дерево также является минимальным остовным деревом графа G, поскольку все вершины G по-прежнему связаны и вес дерева не увеличился. Следовательно E/ принадлежит е можно дополнить до минимального остовного дерева в графе G, то есть ребро е - безопасное 
34. Минимальное покрывающее дерево: жадная стратегия.
**Остовное дерево(spanning** **tree)** графа G = (V, E) – ациклический связный подграф данного связного неориентированного графа, в который входят все его вершины.  
**Минимальное остовное дерево(или минимальное покрывающее дерево)** в 
(неориентированном) связном взвешенном графе – это остовное дерево этого графа, имеющее минимальный возможный вес, где под весом дерева понимается сумма весов входящих в него ребер. 
 Минимум остовных деревьев графа G = (V, E, W) может быть найден применяя процедуру исследования ребер в порядке возрастания их весов. Другими словами, на каждом шаге выбирается новое ребро с наименьшим весом, не образующее циклов с уже выбранными ребрами. Процесс продолжается до тех пор, пока не будет выбрано |V| - 1 ребро. Такая процедура называется **жадным алгоритмом.**  
Другое пояснение: Жадная стратегия (или жадный алгоритм) - это метод решения задач, при котором на каждом шаге выбирается локально оптимальное решение с надеждой, что в итоге будет найдено глобально оптимальное решение. 
35. Алгоритм Прима.
**Остовное дерево(spanning** **tree)** графа G = (V, E) – ациклический связный подграф данного связного неориентированного графа, в который входят все его вершины.  
**Минимальное остовное дерево(или минимальное покрывающее дерево)** в 
(неориентированном) связном взвешенном графе – это остовное дерево этого графа, имеющее минимальный возможный вес, где под весом дерева понимается сумма весов входящих в него ребер. 
 
**Алгоритм Прима** – алгоритм поиска минимального остовного дерева во взвешенном неориентированном связном графе. 
 
Данный алгоритм похож на алгоритм Дейкстры. Будет последовательно строить поддерево F ответа в графе G, поддерживая приоритетную очередь Q из вершин G \ F, в которой ключом для вершины v является min w(uv) – вес минимального ребра из вершин F в вершины G \ F 
 
u принадлежит V(F), uv принадлежит E(G) 
 
Также для каждой вершины в очереди будем хранить p(v) – вершину u, на которой достигается минимум в определении ключа. Дерево F поддерживается неявно, и его ребра – это пары (v, p(u)), где v принадлежит G\{r}\ Q, а r – корень F. Изначально F пусто и значения ключей у всех вершин равны плюс бесконечности. Выберем произвольную вершину r и присвоим ее ключу значение 0. На каждом шаге будем извлекать минимальную вершину v из приоритетной очереди и релаксировать все ребра vu, такие что u принадлежит Q, выполняя при этом операцию decreaseKey 

36. Алгоритм Краскала.


константные различия в скорости их 
работы. На разреженных графах (количество рёбер примерно равно количеству вершин) быстрее работает алгоритм Крускала, а на насыщенных (количество рёбер примерно равно квадрату количеству вершин) - алгоритм Прима (при использовании матрицы смежности). На практике чаще используется алгоритм Крускала. 
 
Будем последовательно строить подграф F графа G (“растущий лес”), пытаясь на каждом шаге достроить F до некоторого MST. Начнем с того, что включим в F все вершины графа G. Теперь будем обходить множество E(G) в порядке неубывания весов ребер. Если очередное ребро е соединяет вершины одной компоненты связности F, то добавление его в остов приведет к возникновению цикла в этой компоненте связности. В таком случае, е не может быть включено в F. Иначе е соединяет разные компоненты связности F, тогда существует <S, T> разрез такой. 
 ``` def Graph():     def __init__(self, vertices): 
        self.V = vertices         self.graph = [] 
     def addEdge(self, u, v, w): 
        self.graph.append([u, v, w]) 
     def find(self, parent, i): 
        if parent[i] != i:             parent[i] = self.find(parent, parent[i])         return parent[i]      def union(self, parent, rank, x, y): 
        if rank[x] < rank[y]: 
            parent[x] = y         elif rank[x] > rank[y]: 
            parent[y] = x         else: 
            parent[y] = x             rank[x] + 1 
     def KruskalMST(self): 
        result = []         i = 0         e = 0 
        self.graph = sorted(self.graph, key=lambda item: item[2])         parent = []         rank = [] 
         for node in range(self.V):             parent.append(node)             rank.append(0) 
37. Система непересекающихся множеств.
**Система непересекающихся множеств (disjoint** **или union-find** **data** **structure**) – структура данных, которая позволяет администрировать множество элементов, разбитое на непересекающиеся подмножества. Абстрактная структура данных определяется множеством трех операций: 
 
{Union, Find, MakeSet} 
 
- make_set(x) – добавляет новый элемент x, помещая его в новое множество, состоящее из одного него. 
- union_sets(x, y) – объединяет два указанных множества(множество, в котором находится элемент x, и множество, в котором находится элемент y) 
- find_set(x) – возвращает, в каком множестве находится указанный элемент x. На самом деле при этом возвращается один из элементов множества(называемый представителем или лидером. Этот представитель выбирается в каждом множестве самой структурой данных (и может меняться с течением времени, после вызовов union_sets()) 
 
Например, если вызов find_set() для каких-то двух элементов вернул одно и то же значение, то это означает, что эти элементы находятся в одном и том же множестве, а в противном случае – в разных множествах. 
38. Представление множеств с помощью деревьев, две эвристики.
**Система непересекающихся множеств (**disjoint **или union-find** **data** 
**structure**) – структура данных, которая позволяет администрировать множество 

элементов, разбитое на непересекающиеся подмножества. 
 
Множества элементов будем хранить в виде деревьев: одно дерево соответствует одному множеству. Корень дерева – это представитель(лидер) множества. 
 При реализации это означает, что мы заводим массив parent, в котором для каждого элемента мы храним ссылку на его предка в дереве. Для корней деревьев будем считать, что их предок – они сами. (т.е. ссылка зацикливается в этом месте) 
 
**Представление множеств с помощью деревьев. Наивная реализация.**  Вся информация о множествах элементов хранится с помощью массива parent. 
 
Чтобы создать новый элемент (операция make_set(v)), просто создаем дерево с корнем в вершине v, отмечая, что ее предок – она сама. 
 Чтобы объединить два множества(операция union_sets(a,b)), сначала найдем лидеров множества, в котором находится a, и множества, в котором находится b. Если лидеры совпали, то ничего не делаем – это значит, что множества уже были объединены. В противном случае можно указать, что предок вершины b равен a(или наоборот) – тем самым присоединив одно дерево к другому.  ``` def union(parent, rank, i, j): 
    irep = find(parent, i)     jrep = find(parent, j)     parent[irep] = jrep 
``` 
 
Реализация операции поиска лидера(find_set(v)) проста: поднимаемся по предкам от вершины v, пока не дойдем до корня, т.е. пока ссылка на предка не ведет в себя. Эту операцию удобнее реализовать рекурсивно. 
 ``` def find(i, parent):     if (parent[i] == i): 
        return i     else: 
        return find(parent[i], parent) 
``` 
 
Такая реализация непересекающихся множеств весьма неэффективна. Легко построить пример, когда после нескольких объединений получится ситуация, что множество – это дерево, выродившееся в длинную цепочку. В результате каждый вызов find_set() будет работать в таком тесте за время порядка глубины дерева, т.е. 
за O(n) 
 
**Первая эвристика – Эвристика сжатия пути** 
 
Эта эвристика предназначена для ускорения работы find_set(). 
 
Она заключается в том, что когда после вызова find_set(v) мы найдем искомого лидера p множества, то запомним, что у вершины  v и всех пройденных до пути вершин – именно это лидер p. Проще всего это сделать, перенаправив их parent[] на эту вершину p. Таким образом, у массива предков parent[] смысл несколько меняется: теперь это сжатый массив предков, т.е. для каждой вершины там может храниться предок предка, предок предка предка и т.д. 
 
С другой стороны, нельзя сделать, чтобы эти указатели parent всегда указывали на лидера: иначе при выполнении операции union_sets() пришлось бы обновлять лидеров у O(n) элементов. Таким образом, к массиву parent[] следует подходить именно как к массиву предков, возможно, частично сжатому. 
 
**Вторая эвристика – Эвристика объединения по рангу.** 
 
Она ускоряет время работы алгоритма, а в сочетании с эвристикой сжатия путей и вовсе способна достигнуть практически константного времени работы на один запрос в среднем. 
 
Эта эвристика заключается в небольшом изменении работы union_sets: если в наивной реализации то, какое дерево будет присоединено к какому, определяется случайно, то теперь мы будет делать это на основе рангов. 
 
Два варианта ранговой эвристики: В одном варианте рангом дерева называется количество вершин в нем, а в другом – глубина дерева(точнее – верхняя глубина дерева может уменьшаться) 
 
В обоих вариантах суть эвристики одна и та же: при выполнении unions_sets будем присоединять дерево с меньшим рангом к дереву с большим рангом. 
 **Объединение эвристик** 
 ``` class DisjSet:     def __init__(self, n):         self.rank = [1] * n 
        self.parent = [i for i in range(n)] 
     def find(self, x): 
        if self.parent[x] != x:             self.parent[x] = self.find(self.parent[x])         return self.parent[x] 
     def Union(self, x, y):         xset = self.find(x)         yset = self.find(y)         if xset == yset: 
            return         if self.rank[xset] < self.rank[yset]: 

42. Деревья. Бинарные деревья.
**Дерево** — это связный ациклический граф. Связность означает наличие маршрута между любой парой вершин, ацикличность — отсутствие циклов. Отсюда, в частности, следует, что число рёбер в дереве на единицу меньше числа вершин, а между любыми парами вершин имеется один и только один путь. 
 
**Ориентированное (направленное) дерево** — ацикличный орграф, в котором только одна вершина имеет нулевую степень захода (в неё не ведут дуги), а все 

остальные вершины имеют степень захода 1 (в них ведёт ровно по одной дуге). Вершина с нулевой степенью захода называется корнем дерева, вершины с нулевой степенью исхода (из которых не исходит ни одна дуга) называются концевыми вершинами или листьями. 
 
**Двоичное дерево (Бинарное дерево)** — иерархическая структура данных, в которой каждый узел имеет не более двух потомков (детей). Как правило, первый называется родительским узлом, а дети называются левым и правым наследниками. Двоичное дерево является упорядоченным ориентированным деревом. Для практических целей обычно используют два подвида двоичных деревьев — двоичное дерево поиска и двоичная куча. 
 
**Бинарные деревья. Представление в виде списка.** 
 ``` tree = [None] * 10 def root(key): 
    if tree[0] != None: 
        print('Дерево уже содержит корень')     else: 
        tree[0] = key 
 def set_left(key, parent):     if tree[parent] == None: 
        print('Невозможно установить потомка в', (parent * 2) + 1, ',родитель не найден')     else: 
        tree[(parent * 2) + 1] = key 
 def set_right(key_parent):     if tree[parent] = None: 
        print('Невозможно установить потомка в', (parent * 2) + 2), ',родитель не найден'     else: 
        tree[(parent * 2) + 2] = key 
 
``` 
 
**Динамическое представление узлов бинарного дерева** 
 
Каждый узел дерева содержит следующую информацию: 
 
- Данные 
- Указатель на левого потомка 
- Указатель на правого потомка 
 ``` class Node: 
    def __init__(self, key): 
        self.left = None 
        self.right = None         self.data = key 
``` 
 
**Основные операции с бинарным деревом:** 
 
- Вставка элемента 
- Удаление элемента 
- Поиск элемента 
- Удаление элемента по значению 
- Обход дерева 
 
Дополнительные операции с бинарным деревом: 
 
- Нахождение высоты дерева 
- Нахождение слоя дерева 
- Нахождение размера дерева 
 
**Применение бинарных деревьев:** 
 
- В компиляторах, в частности для выполнения арифметических выражений 
- Деревья кодирования Хаффмана в алгоритмах сжатия 
- Очереди с приоритетом 
- Представления иерархических данных 
- В табличных редакторах 
- Для индексирования баз данных и кэша 
- Для быстрого поиска 
- Выделения памяти в компьютерах 
- Операций кодирования и декодирования 
- Для получения и организации информации из больших объемов данных 
- В моделях принятия решений 
- В алгоритмах сортировки 
 
**Обход бинарных деревьев** 
 
Обход осуществляется на основе двух алгоритмов: BFS, DFS 
 
Обход дерева с использованием поиска в глубину(DFS) может быть разбит на 3 вида: 
 
- **Прямой обход(NLR)** 
1. Проверяем, не является ли текущий узел пустым или None 
2. Показываем поле данных корня(или текущего узла) 
3. Обходим левое поддерево рекурсивно, вызвав функцию прямого обхода 
4. Обходим правое поддерево рекурсивно, вызвав функцию прямого обхода. - **Центрированный обход(LNR)** 
1. Проверяем, не является ли текущий узел пустым или None 
2. Обходим левое поддерево рекурсивно, вызвав функцию центрированного обхода 
3. Показываем поле данных корня(или текущего узла) 
4. Обходим правое поддерево рекурсивно, вызвав функцию центрированного обхода 
43. Деревья поиска.


44. Красно-чёрные деревья.
**Бинарное дерево поиска (binary search tree, BST)** — структура данных для работы с упорядоченными множествами 
 
Бинарное дерево поиска обладает следующим свойством: если x – узел бинарного дерева с ключом k, то все узлы в левом поддереве должны иметь ключи меньше k, а в правом больше k. 
 
Основным преимуществом двоичного дерева поиска перед другими структурами данных является возможная высокая эффективность реализации основанных на нем алгоритмов поиска и сортировки. 
 
**Красно-чёрное дерево (англ. red-black tree)** — двоичное дерево поиска, в котором баланс осуществляется на основе "цвета" узла дерева, который принимает только два значения: "красный" (англ. red) и "чёрный" (англ. black). 
 
При этом все листья дерева являются фиктивными и не содержат данных, но относятся к дереву и являются чёрными. 
 Для экономии памяти фиктивные листья можно сделать одним общим фиктивным листом. 
 
Красно-черным называется бинарное поисковое дерево, у которого каждому узлу сопоставлен дополнительный атрибут – цвет и для которого выполняются следующие свойства: 
 
1. Каждый узел промаркирован красным или черным цветом 
2. Корень и конечные узлы(листья) дерева – черные 
3. У красного узла родительский узел – черный 
4. Все простые пути из любого узла х до листьев содержат одинаковое количество черных узлов 
5. Черный узел может иметь черного родителя  
**Вставка элемента в красно-черных деревьях** 
 

Каждый элемент вставляется вместо листа, поэтому для выбора места вставки идём от корня до тех пор, пока указатель на следующего сына не станет None (то есть этот сын — лист). Вставляем вместо него новый элемент с нулевыми потомками и красным цветом. Теперь проверяем балансировку. Если отец нового элемента черный, то никакое из свойств дерева не нарушено. Если же он красный, то нарушается свойство 3, для исправления достаточно рассмотреть два случая:  
1. “Дядя” этого узла тоже красный. Тогда, чтобы сохранить свойства 3 и 4, просто перекрашиваем “отца” в “дядю” в черный цвет, а “деда” – в красный. В таком случае черная высота в этом поддереве одинакова для всех листьев и у всех красных вершин “отцы” черные. Проверяем, не нарушена ли балансировка. Если в результате этих перекрашиваний мы дойдем до корня, то в нем в любом случае ставим черный цвет, чтобы дерево удовлетворяло свойству 2. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/f1f25bfe-d550-40cc-842b-f53886d7e6a0/Untitled.png)  
1. “Дядя” черный. Если выполнить только перекрашивание, то может нарушиться постоянство черной высоты дерева по всем ветвям. Поэтому выполняем поворот. Если добавляемый узел был правым потомком, то необходимо сначала выполнить левое вращение, которое сделает его левым потомком. Таким образом, свойство 3 и постоянство черной высоты сохраняются. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/d102f610-fd18-4b2a-9a77-6150894f1f05/Untitled.png) 
 
**Удаление вершины** 
 
При удалении вершины могут возникнуть три случая в зависимости от количества её детей: 
 
1. Если у вершины нет детей, то изменяем указатель на неё у родителя на None . 2. Если у неё только один ребёнок, то делаем у родителя ссылку на него вместо этой вершины. 3. Если же имеются оба ребёнка, то находим вершину со следующим значением ключа. У такой вершины нет левого ребёнка (так как такая вершина находится в правом поддереве исходной вершины и она самая левая в нем, иначе бы мы взяли ее левого ребенка. Иными словами сначала мы переходим в правое поддерево, а после спускаемся вниз в левое до тех пор, пока у вершины есть левый ребенок). Удаляем уже эту вершину описанным во втором пункте способом, скопировав её ключ в изначальную вершину. 
 
Проверим балансировку дерева. Так как при удалении красной вершины свойства дерева не нарушаются, то восстановление балансировки потребуется только при удалении чёрной. Рассмотрим ребёнка удалённой вершины. 
 
Если брат этого ребенка красный, то делаем вращение вокруг ребра между отцом и братом, тогда брат становится родителем отца. Красим его в черный, а отца – в красный цвет, сохраняя таким образом черную высоту дерева. Хотя все пути попрежнему содержат одинаковое количество черных узлов, сейчас х имеет черного 
брата и красного отца. Таким образом, можно перейти к следующему шагу  
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/1357316b-2456-49e6-a5bd-905483e38d53/Untitled.png)  
Оба ребёнка у брата чёрные. Красим брата в красный цвет и рассматриваем далее отца вершины. Делаем его черным, это не повлияет на количество чёрных узлов на путях, проходящих через b, но добавит один к числу чёрных узлов на путях, проходящих через x, восстанавливая тем самым влияние удаленного чёрного узла. Таким образом, после удаления вершины черная глубина от отца этой вершины до всех листьев в этом поддереве будет одинаковой. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/5fa15946-0d08-4d15-8f9f-b0fb7879972c/Untitled.png)  
Если у брата правый ребёнок чёрный, а левый красный, то перекрашиваем брата и его левого сына и делаем вращение. Все пути по-прежнему содержат одинаковое количество чёрных узлов, но теперь у x есть чёрный брат с красным правым потомком, и мы переходим к следующему случаю. Ни x, ни его отец не влияют на эту трансформацию. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/2b682586-1d0d-4a8a-adc9-7a3d67d946c6/Untitled.png)  
Если у брата правый ребёнок красный, то перекрашиваем брата в цвет отца, его ребёнка и отца — в чёрный, делаем вращение. Поддерево по-прежнему имеет тот же цвет корня, поэтому свойство 3 и 4 не нарушаются. Но у x теперь появился дополнительный чёрный предок: либо a стал чёрным, или он и был чёрным и b был добавлен в качестве чёрного дедушки. Таким образом, проходящие через x пути проходят через один дополнительный чёрный узел. Выходим из алгоритма. 
 
![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3637e689-bc67-
4d3a-8b63-8916d6b20447/8cb69d0a-e7f5-4be4-b346-4f9af30e917c/Untitled.png)  **Преимущества красно-черных деревьев**: 
 
1. Самое главное преимущество красно-черных деревьев в том, что при вставке выполняется не более O(1) вращений. 
2. Процедуру балансировки практически всегда можно выполнять параллельно с процедурами поиска, так как алгоритм поиска не зависит от атрибута цвета узлов. 3. Сбалансированность этих деревьев хуже, чем у АВЛ, но работа по поддержанию сбалансированности в красно-черных деревьях обычно эффективнее. Для балансировки красно-черного дерева производится минимальная работа по сравнению с АВЛ-деревьями. 
4. Использует всего 1 бит дополнительной памяти для хранения цвета вершины. 
 
Красно-чёрные деревья являются наиболее активно используемыми на практике самобалансирующимися деревьями поиска. В частности, ассоциативные контейнеры библиотеки STL(map, set, multiset, multimap) основаны на красно-чёрных деревьях. TreeMap в Java тоже реализован на основе красно-чёрных деревьев 
45. AVL-деревья.

ключа t. Если мы стоим в вершине a и нам надо идти в поддерево, которого нет, то делаем ключ t листом, а вершину a его корнем. Дальше поднимаемся вверх по пути поиска и пересчитываем баланс у вершин. Если мы поднялись в вершину i из левого поддерева, то diff[i] увеличивается на единицу, если из правого, то уменьшается на единицу. Если пришли в вершину и её баланс стал равным нулю, то это значит высота поддерева не изменилась и подъём останавливается. Если пришли в вершину и её баланс стал равным 1 или -1 , то это значит высота поддерева изменилась и подъём продолжается. Если пришли в вершину и её баланс стал равным 2 или -2, то делаем одно из четырёх вращений и, если после вращения баланс стал равным нулю, то останавливаемся, иначе продолжаем подъём. 
 
Так как в процессе добавления вершины мы рассматриваем не более, чем O(h) вершин дерева, и для каждой запускаем балансировку не более одного раза, то суммарное количество операций при включении новой вершины в дерево составляет 
O(logn) операций. 
 
**Удаление вершины** 
 
Для простоты опишем рекурсивный алгоритм удаления. Если вершина — лист, то удалим её, иначе найдём самую близкую по значению вершину a, переместим её на место удаляемой вершины и удалим вершину a. От удалённой вершины будем подниматься вверх к корню и пересчитывать баланс у вершин. Если мы поднялись в вершину из левого поддерева, то diff[i] уменьшается на единицу, если из правого, то увеличивается на единицу. Если пришли в вершину и её баланс стал равным 1 или -1, то это значит, что высота этого поддерева не изменилась и подъём можно остановить. Если баланс вершины стал равным нулю, то высота поддерева уменьшилась и подъём нужно продолжить. Если баланс стал равным 2 или -2, следует выполнить одно из четырёх вращений и, если после вращений баланс вершины стал равным нулю, то подъём продолжается, иначе останавливается.  
В результате указанных действий на удаление вершины и балансировку суммарно тратится, как и ранее, O(h) операций. Таким образом, требуемое количество действий —  O(logn). 
46. B деревья.
**В-дерево** — структура данных, дерево поиска. С точки зрения внешнего логического представления — сбалансированное, сильно ветвистое дерево. Часто используется для хранения данных во внешней памяти. 
 
Использование B-деревьев впервые было предложено Р. Бэйером и Э. МакКрейтом в 
1970 году. 
 
С точки зрения физической организации B-дерево представляется как мультисписочная структура страниц памяти, то есть каждому узлу дерева соответствует блок памяти (страница). Внутренние и листовые страницы обычно имеют разную структуру. Структура B-дерева применяется для организации индексов во многих современных СУБД. 

 
В-деревом называется дерево, удовлетворяющее следующим свойствам: 
 
1. Ключи в каждом узле обычно упорядочены для быстрого доступа к ним. Корень содержит от 1 до 2t-1 ключей. Любой другой узел содержит от t-1 до 2t-1 ключей. Листья не являются исключением из этого правила. Здесь t — параметр дерева, не меньший 2 (и обычно принимающий значения от 50 до 2000). 
2. У листьев потомков нет. Любой другой узел, содержащий ключи K, …, Kсодержит n+1 потомков. При этом: 
 
i. Первый потомок и все его потомки содержат ключи из интервала (-бесконечность, K) 
 
ii. Для 2<=i<=n, i-й потомок и все его потомки содержат ключи из интервала (K, 
K)  iii. (n+1)-й потомок и все его потомки содержат ключи из интервала (K, бесконечность) 
 
1. Глубина всех листьев одинакова. 
 
Свойство 2 можно сформулировать иначе: каждый узел B-дерева, кроме листьев, можно рассматривать как упорядоченный список, в котором чередуются ключи и указатели на потомков. 
 
- Во всех случаях полезное использование пространства вторичной памяти составляет свыше 50 %. С ростом степени полезного использования памяти не происходит снижения качества обслуживания. 
- Произвольный доступ к записи реализуется посредством малого количества подопераций (обращения к физическим блокам). - В среднем достаточно эффективно реализуются операции включения и удаления записей; при этом сохраняется естественный порядок ключей с целью последовательной обработки, а также соответствующий баланс дерева для обеспечения быстрой произвольной выборки. 
- Неизменная упорядоченность по ключу обеспечивает возможность эффективной пакетной обработки 
 
Основной недостаток B-деревьев состоит в отсутствии для них эффективных средств выборки данных(то есть метода обхода дерева), упорядоченных по свойству, отличному от выбранного ключа. 
 
**Вставка в В-деревьях.** 
 
1. Если дерево пустое, добавить корень и вставить значение. 
2. Обновить количество ключей в узле. 
3. Найти подходящий для вставки узел. 
4. Если узел полон, то: 
 
i. Вставить элемент в порядке возрастания. 
 ii. Так как количество элементов больше предела, разбить узел по медиане. 
 iii. Сместить медианный ключ вверх и сделать ключи слева левым потомком, а ключи справа – правым. 
 
1. Если узел не полон, то: 
 
i. Вставить элемент в порядке возрастания. 
 
**B* деревья** 
 
Что они делают здесь? Да, я, если честно, тоже слегка в шоке. Итак, да потому, что это разновидность B-дерева, в которой каждый узел дерева заполнен не менее чем на 2/3(в отличие от B-дерева, где этот показатель составляет ?). B* - деревья предложили Рудольф Байер и Эдвард МакКрейт, изучавшие проблему компактности В-деревьев. В*-дерево относительно компактнее, так как каждый узел используется полнее. В остальном этот вид деревьев не отличается от простого Вдерева. 
Для выполнения требования “заполненность узла не менее 2/3” приходится отказываться от простой процедуры разделения переполненного узла. Вместо этого происходит “переливание” в соседний узел. Если же соседний узел заполнен, то ключи приблизительно поровну разделяются на 3 новых узла. 
В+-дерево, удовлетворяющее таким требованиям, называется B*+ деревом 
47. B+ деревья.
**B+-дерево –** структура данных на основе В-дерева, сбалансированное n-aрное дерево поиска с переменным, но зачастую большим количеством потомков в узле. В+-дерево состоит из корня, внутренних узлов и листьев, корень может быть либо листом, либо узлом с двумя и более потомками. 
 
Изначально структура предназначалась для хранения данных в целях эффективного поиска в блочно-ориентированной среде хранения — в частности, для файловых систем; применение связано с тем, что в отличие от бинарных деревьев поиска, B?-деревья имеют очень высокий коэффициент ветвления (число указателей из родительского узла на дочерние — обычно порядка 100 или более), что снижает количество операций ввода-вывода, требующих поиска элемента в дереве. Структура широко применяется в файловых системах — NTFS, ReiserFS, NSS, XFS, JFS, ReFS и BFS используют этот тип дерева для индексирования метаданных; BeFS также использует B?-деревья для хранения каталогов. Реляционные системы управления базами данных, такие как DB2, Informix, Microsoft SQL Server, Oracle Database (начиная с версии 8), Adaptive Server Enterprise и SQLite поддерживают этот тип деревьев для табличных индексов.  
**В+-деревом называется дерево, удовлетворяющее следующим свойствам:**  
1. Ключи в каждом узле обычно упорядочены для быстрого доступа к ним. Корень содержит от 1 до 2t-1 ключей. Любой другой узел содержит от t-1 до 2t-1 ключей. 


PROFESSEUR : M.DA ROS	BTS SIO BORDEAUX - LYC?E GUSTAVE EIFFEL
? 1 / 71 ?

PROFESSEUR : M.DA ROS	BTS SIO BORDEAUX - LYC?E GUSTAVE EIFFEL
? 1 / 71 ?

PROFESSEUR : M.DA ROS	BTS SIO BORDEAUX - LYC?E GUSTAVE EIFFEL
? 1 / 71 ?

